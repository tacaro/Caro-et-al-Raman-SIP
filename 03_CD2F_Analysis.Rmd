---
title: "03_CD2F_Analysis"
author: "Tristan Caro"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Setup

## Clear the environment

```{r}
rm(list=ls())
```

## Load libraries

```{r}
library(tidyverse)
library(magrittr)
library(tidyverse)
library(cowplot)
library(latex2exp)
library(ggside)
library(ggsci)
library(ggdist)
```

## Load from cache

```{r}
excluded_cells <- readxl::read_excel("data/other/excluded_cells.xlsx") %>% pull(cell_id)

# Co registered datasets
co_registered_fit <- readRDS("cache/co_registered_fitted.RDS") |> 
  # Fix methanobacterium name to be M. NSHQ04 (not NSHQ14)
  mutate(organism = case_when(
    organism == "M. NSHQ14" ~ "M. NSHQ04", # if incorrect, switch it
    TRUE ~ organism # else, return original value
    )
  )

# Raman data
cd_pc_data_fitted <- readRDS("cache/area_data.RDS")

# NanoSIMS data
nanoSIMS_data <- readRDS("cache/roi_data_joined.RDS") |> 
  # Exclude cells on the excluded cells list
  filter(!cell_id %in% excluded_cells) 

# Fitted xy data
fit_data <- readRDS("cache/fit_data.RDS")

# Fitting parameter data
fitted_xy_data <- readRDS("cache/peak_data_xy.RDS")
```

## Load from source

```{r}
calculate_growth <- source("source/Calculate_Growth.R")
```

# Proxy generation

```{r}
proxy_data <- broom::tidy(lm(data = co_registered_fit, `CD%`  ~ at2H_percent_dtc))
proxy_y_int <- proxy_data %>% 
  filter(term == "(Intercept)") %>%
  select(estimate) %>% 
  pull()

proxy_slope <- proxy_data %>% 
  filter(term == "at2H_percent_dtc") %>% 
  select(estimate) %>% 
  pull()
```

# Proxy generation - SRB

```{r}
proxy_data_SRB <- broom::tidy(lm(
  data = co_registered_fit %>% filter(organism == "T. hydrogeniphilus"), 
  `CD%`  ~ at2H_percent_dtc))
proxy_y_int_SRB <- proxy_data_SRB %>% 
  filter(term == "(Intercept)") %>%
  select(estimate) %>% 
  pull()

proxy_slope_SRB <- proxy_data_SRB %>% 
  filter(term == "at2H_percent_dtc") %>% 
  select(estimate) %>% 
  pull()
```

# Proxy generation - Mb

```{r}
proxy_data_Mb <- broom::tidy(lm(
  data = co_registered_fit %>% filter(organism == "M. NSHQ04"), 
  `CD%`  ~ at2H_percent_dtc))
proxy_y_int_Mb <- proxy_data_Mb %>% 
  filter(term == "(Intercept)") %>%
  select(estimate) %>% 
  pull()

proxy_slope_Mb <- proxy_data_Mb %>% 
  filter(term == "at2H_percent_dtc") %>% 
  select(estimate) %>% 
  pull()
```

# Calculate assimilation efficiency

The hydrogen assimilation efficiency from water $a_{water}$ or simply referred to here as $a$ is defined as the fraction of an organism's biomass hydrogen that is acquired from its growth water as opposed to other sources. $a$ is therefore a fraction between zero and 1, with `1` representing "all H sourced from water," `0.5` representing "50% of H sourced from water, 50% from other sources (e.g., carbon source)," etc.

$a$ is calculated as the incorporation of $D_2O$ over multiple label strengths. In essence, the slope of the line of `x = label strength` and `y = biomass at2H` as label strength increases.

$a$ is a crucial component of growth rate calculations, as it defines the maximum enrichment an organism can ostensibly reach in the presence of tracer. For example, if an organism is grown in 50% $D_2O$ and it has an `a = 0.9`, its maximum enrichment would be `0.9*50% = 45 %`.

Here we calculate `a` using both Raman and nanoSIMS data but report a using Raman data, for reasons discussed in the manuscript. In brief, we want to be sure we are measuring non-exchangable H, which we believe Raman is indeed measuring.

```{r}
co_registered_fit_slim <- co_registered_fit |> 
  filter(f_l < 50) |> 
  select(
    f_l, 
    `CD%`,
    at2H_percent_dtc,
    organism
    )

raman_assim_data <- co_registered_fit_slim |> 
  select(!at2H_percent_dtc) |> 
  group_by(organism) |> 
  # nest the data for a linear model
  tidyr::nest(
    raman_data = c(`CD%`, f_l),
    #SIMS_data = c(at2H_percent_dtc, f_l),
  ) |> 
  # generate linear models and output the data in a tidy format
  mutate(
    raman_fit = purrr::map(raman_data, ~lm(`CD%` ~ f_l, data = .x)),
    #SIMS_fit = purrr::map(SIMS_data, ~lm(at2H_percent_dtc ~ f_l, data = .x)),
    raman_estimates = purrr::map(raman_fit, broom::tidy),
    #SIMS_estimates = purrr::map(SIMS_fit, broom::tidy),
    raman_summary = purrr::map(raman_fit, broom::glance),
    #SIMS_summary = purrr::map(SIMS_fit, broom::glance)
  ) %>% tidyr::unnest(c(raman_estimates)) |> 
  mutate(method = "Raman") |> 
  select(method, organism, term, estimate, std.error, statistic, p.value)

SIMS_assim_data <- co_registered_fit_slim |> 
  select(!`CD%`) |> 
  group_by(organism) |> 
  # nest the data for a linear model
  tidyr::nest(
    #raman_data = c(`CD%`, f_l),
    SIMS_data = c(at2H_percent_dtc, f_l),
  ) |> 
  # generate linear models and output the data in a tidy format
  mutate(
    #raman_fit = purrr::map(raman_data, ~lm(`CD%` ~ f_l, data = .x)),
    SIMS_fit = purrr::map(SIMS_data, ~lm(at2H_percent_dtc ~ f_l, data = .x)),
    #raman_estimates = purrr::map(raman_fit, broom::tidy),
    SIMS_estimates = purrr::map(SIMS_fit, broom::tidy),
    #raman_summary = purrr::map(raman_fit, broom::glance),
    SIMS_summary = purrr::map(SIMS_fit, broom::glance)
  ) %>% tidyr::unnest(c(SIMS_estimates)) |> 
  mutate(method = "nanoSIMS") |> 
  select(method, organism, term, estimate, std.error, statistic, p.value)


# Make a lil' summary tibble
assim_data <- bind_rows(raman_assim_data, SIMS_assim_data) |> 
  filter(term != "(Intercept)") |> 
  mutate(term = case_when(term == "f_l" ~ "a"))

knitr::kable(assim_data)

# Write the data
writexl::write_xlsx(assim_data, path = "data_output/assim_data.xlsx")

```

# Calculate SD/SE

Here we estimate the standard deviation (SD) of each set of samples (grouped by label strength and method). Standard deviations are used for downstream error propagation.

Here we estimate the standard error (SE) as the standard error of the mean. The standard deviation $\sigma$ of the population being sampled, in this case, cannot be known. Therefore, the SE of the mean is estimated by replacing $\sigma$ with the sample standard deviation $\sigma_x$.

Here, the use of standard error is appropriate

$$
s_{\bar{x}} = \frac{\sigma_x}{\sqrt{n}}
$$

```{r}
co_registered_fit_summarized <- co_registered_fit |> 
  group_by(organism, f_l) |> 
  summarize(
    mean_cdpc = mean(`CD%`, na.rm = TRUE),
    sd_cdpc = sd(`CD%`, na.rm = TRUE),
    mean_2F = mean(at2H_percent_dtc, na.rm = TRUE),
    sd_2F = sd(at2H_percent_dtc, na.rm = TRUE),
    n = n()
    ) |> 
  mutate(
    # calculate SE from the sample standard deviation
    SE_cdpc = sd_cdpc / sqrt(n),
    SE_2F = sd_2F / sqrt(n)
  )

co_registered_fit_summarized |> knitr::kable()

# write the data
co_registered_fit_summarized |> writexl::write_xlsx(path = "data_output/coreg_summarized.xlsx")

co_registered_fit_summarized |> 
  summarize(
    SE_total_cdpc = mean(SE_cdpc),
    SE_total_2F = mean(SE_2F)
  )
```

### SE of all cells

#### Raman

```{r}
# Raman
SE_summary_raman <- co_registered_fit |> 
  group_by(f_l) |> 
  summarize(
    mean_cdpc = mean(`CD%`, na.rm = TRUE),
    sd_cdpc = sd(`CD%`, na.rm = TRUE),
    n = n()
  ) |> 
  mutate(
    # calculate SE from the sample standard deviation
    SE_cdpc = sd_cdpc / sqrt(n)
  )

writexl::write_xlsx(SE_summary_raman, path = "data_output/SE_summary_raman.xlsx")
  
```

#### NanoSIMS

```{r}
SE_summary_SIMS <- co_registered_fit |> 
  group_by(f_l) |> 
  summarize(
    mean_2F = mean(at2H_percent_dtc, na.rm = TRUE),
    sd_2F = sd(at2H_percent_dtc, na.rm = TRUE),
    n = n()
  ) |> 
    mutate(
    # calculate SE from the sample standard deviation
    SE_2F = sd_2F / sqrt(n)
  )
SE_summary_SIMS |> pull(sd_2F) |> mean()

writexl::write_xlsx(SE_summary_SIMS, path = "data_output/SE_summary_SIMS.xlsx")
```


### SE of the method blank

```{r}
co_registered_fit |> 
  filter(f_l == 0) |> 
  summarize(
    mean_cdpc = mean(`CD%`, na.rm = TRUE),
    sd_cdpc = sd(`CD%`, na.rm = TRUE),
    mean_2F = mean(at2H_percent_dtc, na.rm = TRUE),
    sd_2F = sd(at2H_percent_dtc, na.rm = TRUE),
    n = n()
    ) |> 
  mutate(
    # calculate SE from the sample standard deviation
    SE_cdpc = sd_cdpc / sqrt(n),
    SE_2F = sd_2F / sqrt(n)
  )
```


## Quickplot the SD

```{r}
co_registered_fit_summarized |> 
  pivot_longer(cols = c(sd_cdpc, sd_2F), names_to = "method", values_to = "SD") |> 
  mutate(method = case_match(method,
    "sd_2F" ~ "nanoSIMS",
    "sd_cdpc" ~ "Raman"
  )) |> 
  ggplot(aes(
    x = f_l,
    y = SD,
    fill = method
  )) +
  geom_col(position = position_dodge(5), width = 5, color = "black") +
  facet_wrap(vars(organism)) +
  scale_fill_manual(values = c("black", "white")) +
  coord_cartesian(expand = FALSE, xlim = c(-5, 60)) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_x_continuous(labels = scales::percent_format(scale = 1),
                     breaks = c(0, 10, 20, 30, 40, 50)) +
  theme_bw() +
  labs(
    x = latex2exp::TeX("Tracer Strength $^2F $ (at. %)"),
    y = latex2exp::TeX("$\\sigma_{^2F}$ (at. %)"),
    fill = "Method"
  )
```

## Quickplot the SE

In the case the SE is to be used:

```{r}
co_registered_fit_summarized |> 
  # Pivot columns to separate out by raman or nanosims
  pivot_longer(
    cols = c(SE_cdpc, SE_2F),
    names_to = "method",
    values_to = "SE"
  ) |> 
  # Rename the values to be human readable
  mutate(
    method = case_match(
      method,
      "SE_cdpc" ~ "Raman",
      "SE_2F" ~ "nanoSIMS"
    )
  ) |> 
  ggplot() +
  aes(
    x = f_l,
    y = SE,
    #fill = method,
    color = method
  ) +
  geom_line() +
  ggsci::scale_color_jco() +
  ggsci::scale_fill_jco() +
  theme_classic() +
  labs(
    x = latex2exp::TeX("Label Strength ($^2F$%)"),
    y = latex2exp::TeX("$s_{\\bar{x}} $"),
    color = ""
  ) +
  theme(
    legend.position = "right"
  )
```

## Save the data summary

```{r}
write_rds(co_registered_fit_summarized, file = "cache/coreg_data_summary.rds")
```


# Linear model of CD/2F versus F_L

Here we calculate the slope and linear intercept of our Raman (CD) and nanoSIMS (2F)- derived data.

```{r}
cdfl_model <- broom::tidy(
  lm(
    data = co_registered_fit %>% 
      filter(f_l < 40), 
    `CD%`  ~ f_l
    )
  )

f2fl_model <- broom::tidy(
  lm(
    data = co_registered_fit %>% 
      filter(f_l < 40),
    at2H_percent_dtc ~ f_l
  )
)
```

# Calculate DF

Here we define dilution factor (DF) as:

$$
DF = \frac{F_{after} - F_{before}}{F_{added} - F_{before}}
$$ 
where F denotes isotope fraction (at. %) of biomass before and after sample preparation, as well as that of the diluent material ($F_{added}$).

Here, we take the Raman-derived $^2F$ as the *before* value, the nanoSIMS as the *after* value, and natural abundance hydrogen as the *added* value. Because the natural abundance of deuterium is negligible in comparison to the label strengths used for this study, we set $F_{added} = 0 \%$.

For the uncertainty in the DF, we use propagation of uncertainty by quadriture by calculating hte partial derivatives of the equation with respect to each variable. We convert the equation to the following for ease of reading:

$$
D = \frac{A - B}{C - B}
$$

where:

$$
\begin{aligned}
A &= F_{after} \\
B &= F_{before} \\
C &= F_{added} \\
\end{aligned} \\
$$


$$
\begin{aligned}

\sigma_{D} = \sqrt{
\left(\frac{\partial D}{\partial A} \sigma_A\right)^2 + \left(\frac{\partial D}{\partial B} \sigma_B\right)^2 + \left(\frac{\partial D}{\partial C} \sigma_C\right)^2
}

\end{aligned}
$$

Taking the partial derivatives of DF with respect to A, B, and C:

$$
\begin{aligned}
\sigma_A = \frac{\partial D}{\partial A} &= \frac{1}{C-B} \\

\sigma_B =\frac{\partial D}{\partial B} &= \frac{A-C}{(C-B)^2} \\

\sigma_C = \frac{\partial D}{\partial C} &= \frac{B-A}{(C-B)^2} \\

\end{aligned}
$$

Substituting these in to the formula for propagated uncertainty:

$$
\begin{aligned}

\sigma_D &= \sqrt{
\left(\frac{\partial D}{\partial A} \cdot \sigma_A\right)^2 +
\left(\frac{\partial D}{\partial B} \cdot \sigma_B\right)^2 +
\left(\frac{\partial D}{\partial C} \cdot \sigma_C\right)^2
}

\\ \\

\sigma_D &= \sqrt{
\left(\frac{1}{C-B} \cdot \sigma_A\right)^2 +
\left(\frac{A-C}{(C-B)^2} \cdot \sigma_B\right)^2 +
\left(\frac{B-A}{(C-B)^2} \cdot \sigma_C\right)^2
}

\end{aligned}
$$



```{r}
calculate_sigma_DF <- function(A, B, C, sA, sB, sC) {
  sigma_DF <- sqrt(
    (( 1/ (C-B) * sA)^2 ) +
      
    ((( (A-C) / (C-B)^2 * sB)^2) +
      
    (( (B-A) / (C-B)^2) * sC)^2)
  )
  return(sigma_DF)
}


```

```{r}
# Define a natural abundance value. Here we use VSMOW as natural abundance differences
# Are negligible in comparison to at. % values

R_VSMOW <- 0.0001557632399 #2H/1H
F_VSMOW <- R_VSMOW / (1 + R_VSMOW) # 2H / (1H + 2H)

dilution_factors <- co_registered_fit_summarized |> 
  filter(!f_l %in% c(0)) |>
  rename(
    F_before = mean_cdpc,
    F_after = mean_2F,
    sF_before = sd_cdpc,
    sF_after = sd_2F
  ) |> 
  mutate(
    F_added = F_VSMOW,
    sF_added = 0 # assume no uncertainty in what constitutes "natural abundance"
  ) |> 
  # calculate DF:
  mutate(
    DF = (F_after - F_before) / (F_added - F_before),
    sDF = calculate_sigma_DF(
      A = F_after,
      B = F_before,
      C = F_added,
      sA = sF_after,
      sB = sF_before,
      sC = sF_added
    )
  )
  
calculated_mean_DF <- dilution_factors |> pull(DF) |> mean()

calculated_sd_DF <- dilution_factors |> pull(DF) |> sd()


```


## Plot the DF and sDF

```{r}
dilution_factors |> 
  ggplot(
    aes(
      x = f_l,
      y = DF
    )
  ) +
  geom_col() +
  geom_point() +
  geom_errorbar(
    width = 3,
    aes(
      ymin = DF - sDF,
      ymax = DF + sDF)
  ) +
  geom_hline(yintercept = 0) +
  coord_cartesian(expand = FALSE, xlim = c(0, 55)) +
  theme_classic() +
  labs(
    x = latex2exp::TeX("Label Strength ($^2F$%)"),
    y = latex2exp::TeX("$^2F $ Dilution Factor")
  )
```


# Back-Calculate 2F

Now, we can use our generated DF and error associated with the DF to constrain error that is associated with nanoSIMS-derived estimates of $^2F$

$$
F_{before} = \frac{F_{after} - (F_{added} \cdot DF)}{1 - DF}
$$

Or, using the abbreviations from above:
$$
B = \frac{A - (C \cdot D)}{1 - D}
$$

But, we must also back-propagate the error now associated with DF with the following formula:

$$
\begin{aligned}

\sigma_B &= \sqrt{
\left(\frac{\partial B}{\partial A} \cdot \sigma_A\right)^2 +
\left(\frac{\partial B}{\partial C} \cdot \sigma_C\right)^2 +
\left(\frac{\partial B}{\partial D} \cdot \sigma_D\right)^2
} 
\\ \\ 

\sigma_B &= \sqrt{
\left( \frac{1}{1-D} \cdot \sigma_A\right)^2 +
\left( -\frac{D}{1-D} \cdot \sigma_C\right)^2 +
\left( \frac{A-C}{(1-D)^2} \cdot \sigma_D\right)^2
} 

\end{aligned}
$$



```{r}
calculate_F_before <- function(A, C, D) {
  B <- (A - (C * D)) / (1 - D)
  return(B)
}

calculate_sF_before <- function(A, C, D, sA, sC, sD) {
  sB <- sqrt(
    (((1 / (1-D)) * sA) ^2) +
    (((-(D / (1 - D))) * sC) ^2) +
    (((A - C) / (1 - D)^2) * sD)^2
  )
  return(sB)
}

## TEST: this should evaluate to 3.112...
# calculate_sF_before(A = 4.9, C = .00015, D = 0.56, sA = 0.3, sC = 0, sD = 0.12)
```

```{r}
dilution_factors <- dilution_factors |> 
  mutate(
    F_before_backcalc = calculate_F_before(
      A = F_after,
      C = F_added,
      D = DF
    ),
    sF_before_backcalc = calculate_sF_before(
      A = F_after,
      sA = sF_after,
      C = F_added,
      sC = sF_added,
      D = DF,
      sD = sDF
    )
  )
```

## Plot+Save the back-calc data
```{r}
dilution_factors |> 
  ggplot(
    aes(
      x = f_l,
      y = F_before_backcalc
    )
  ) +
  geom_col() +
  geom_point() +
  geom_errorbar(
    aes(
      ymin = F_before_backcalc - sF_before_backcalc,
      ymax = F_before_backcalc + sF_before_backcalc
    ),
    width = 3
  ) +
  geom_point(
    aes(x = f_l,
        y = F_before),
    color = "red"
    ) +
    geom_errorbar(
    aes(
      ymin = F_before - sF_before,
      ymax = F_before + sF_before
    ),
    width = 3,
    color = "red"
  ) +
  coord_cartesian(expand = FALSE, xlim = c(0, 55)) +
  labs(
      x = latex2exp::TeX("Label Strength ($^2F$%)"),
      y = latex2exp::TeX("$^2F $ Calculated from DF")
    ) +
  theme_classic()

write_rds(dilution_factors, file = "cache/dilution_factors.rds")
```


# Generate test dataset

```{r}
test_data <- tibble(
  experiment = "A",
  a = 1, # assimilation efficiency assumed to be 1
  f_l = 30, # label strength is 30 atom % D2O
  t = 60, # incubation time is 60 days
  f_0 = 0.0000000001, # f0, biomass at t0, assumed to be natural abundance of the deuterium isotope
  f_t = abs(rnorm(
    n = 5000, # number of cells measured
    mean = 10,
    sd = 4
    ))
) %>% 
  mutate(
    f_t = case_when(
      f_t > 30 ~ 30,
      TRUE ~ f_t
    )
  ) %>% 
  mutate(
    u_d = calculate_turnover(
      a = a,
      FL = f_l,
      t = t,
      F0 = f_0,
      FT = f_t
    )
  )
```

### Inspect the f_t distribution

```{r}
# Inspect the distribution
test_data %>% 
  ggplot(
    aes(
      x = f_t
    )
  ) +
  geom_histogram(bins = 100) +
  theme_classic()
```

### Inspect the turnover rates

```{r}
# Inspect the µ
test_data %>% 
  ggplot(
    aes(
      x = u_d
    )
  ) +
  geom_histogram(bins = 100) +
  labs(
    x = latex2exp::TeX("Turnover rate ($d^{-1}$)")
  ) +
  theme_classic()
```

### Apply the proxy to the turnover rates

```{r}
test_data_proxied <- test_data %>% 
  mutate(
    f_t_raman = f_t * proxy_slope,
    f_t_nanoSIMS = f_t / proxy_slope,
    u_d_raman = calculate_turnover(
      a = a,
      FL = f_l,
      t = t,
      F0 = f_0,
      FT = f_t_raman
      ),
    u_d_nanoSIMS = calculate_turnover(
      a = a,
      FL = f_l,
      t = t,
      F0 = f_0,
      FT = f_t_nanoSIMS
      )
    )
```

### Inspect the distribution of f_t

```{r}
test_data_proxied %>% 
  pivot_longer(
    cols = c(f_t, f_t_raman, f_t_nanoSIMS),
    values_to = "f_t",
    names_to = "type"
    ) %>% 
  ggplot(
    aes(
      x = f_t,
      fill = type
    )
  ) +
  stat_halfeye(
    alpha = 0.5
  )
```

### Inspect the distribution of µ

```{r}
test_data_proxied %>% 
  pivot_longer(
    cols = c(u_d, u_d_nanoSIMS),
    values_to = "u_d",
    names_to = "type"
    ) %>% 
  ggplot(
    aes(
      x = u_d,
      fill = type
    )
  ) +
  stat_halfeye(
    alpha = 0.5
  )
```

```{r}
test_data_proxied %>% 
  ggplot(
    aes(
      x = f_t,
      y = f_t_raman
    )
  ) +
  geom_point()
```

```{r}
test_data_proxied %>%
  pivot_longer(cols = c(f_t, f_t_raman),
               names_to = "type",
               values_to = "2F") %>% 
  pivot_longer(
    cols = c(f_0, `2F`),
    names_to = "timepoint",
    values_to = "FT"
  ) %>% 
  mutate(
    dt = case_when(
      timepoint == "f_0" ~ 0,
      timepoint == "2F" ~ 60
    )
  ) %>%
  ggplot(
    aes(x = dt,
        y = FT,
        color = type)
  ) +
  geom_point() +
  geom_line(alpha = 0.5)
```

# Error analysis

```{r}
co_registered_fit_w_se <- co_registered_fit %>% 
  group_by(f_l) %>% 
  summarize(
    mn_cd = mean(`CD%`, na.rm = TRUE),
    mn_2f = mean(at2H_percent_dtc, na.rm = TRUE),
    se_cd = sd(`CD%`, na.rm = TRUE),
    se_2f = sd(at2H_percent_dtc, na.rm = TRUE)
  )
co_registered_fit_w_se

p_co_registered_fit_w_se <- co_registered_fit_w_se %>% 
  ggplot(
    aes(
      x = mn_2f,
      y = mn_cd,
      color = as.factor(f_l),
      shape = organism
    )
  ) +
  geom_point(
    size = 3,
  ) +
  geom_linerange(
    aes(
      ymin = mn_cd - (0.5* se_cd),
      ymax = mn_cd + (0.5* se_cd)
    ),
    linewidth = 1
  ) +
  geom_linerange(
    aes(
      xmin = mn_2f - (0.5 * se_2f),
      xmax = mn_2f + (0.5 * se_2f)
    ),
    linewidth = 1
  ) +
  scale_color_viridis_d(
    option = "magma",
    begin = 0.2,
    end = 0.9
  ) +
  labs(
    x = "Mean 2F (NanoSIMS)",
    y = "Mean CD% (Raman)",
    color = "Label Strength (%)"
  ) +
  theme_classic()

p_co_registered_fit_w_se_inset <- co_registered_fit_w_se %>% 
  ggplot(
    aes(
      x = mn_2f,
      y = mn_cd,
      color = as.factor(f_l)
    )
  ) +
  geom_point(
    size = 3,
    shape = 1
  ) +
  geom_linerange(
    aes(
      ymin = mn_cd - (0.5* se_cd),
      ymax = mn_cd + (0.5* se_cd)
    ),
    linewidth = 1
  ) +
  geom_linerange(
    aes(
      xmin = mn_2f - (0.5 * se_2f),
      xmax = mn_2f + (0.5 * se_2f)
    ),
    linewidth = 1
  ) +
  scale_color_viridis_d(
    option = "magma",
    begin = 0.2,
    end = 0.9
  ) +
  coord_cartesian(xlim = c(0,0.05), ylim = c(0, 5)) +
  labs(
    x = "",
    y = "",
    color = ""
  ) +
  theme_classic()
p_co_registered_fit_w_se_inset
```

### Track Standard Error

```{r}
co_registered_fit_w_se %>% 
  pivot_longer(
    cols = c(se_cd, se_2f),
    names_to = "Method",
    values_to = "se"
  ) %>% 
  ggplot(
    aes(
      x = f_l,
      y = se,
      color = Method,
      fill = Method,
      linetype = organism
    )
  ) + geom_line()
```

### Identify Raman/nanoSIMS measurement error

```{r}
raman_standard_error <- co_registered_fit_w_se %>% 
  filter(f_l == 0) %>% 
  select(se_cd) %>% 
  pull()

nanoSIMS_standard_error <- co_registered_fit_w_se %>% 
  filter(f_l == 0) %>% 
  select(se_2f) %>% 
  pull()
```

```{r}
calculate_turnover(
  a = 1,
  FT = raman_standard_error,
  F0 = 0,
  FL = 30,
  t = 7
)

# Multiply the raman standard error by 2 to assume that 2SD is required to be above BG noise
error_u_d <- tibble(
  a = 0.7,
  error_raman = 2 * raman_standard_error,
  error_nanoSIMS = 2* nanoSIMS_standard_error,
  F0 = 0,
  FL = seq(5,50, by = 1),
  t = 7,
  # Calculate detection limit in turnover (d^-1)
  DLR_u_d = calculate_turnover(
    a = a,
    FT = error_raman,
    FL = FL,
    t = t,
    F0 = F0
  ),
  DLN_u_d = calculate_turnover(
    a = a,
    FT = error_nanoSIMS,
    FL = FL,
    t = t,
    F0 = F0
  )
) %>% 
  pivot_longer(
    cols = c(DLR_u_d, DLN_u_d),
    values_to = "DL_u_d",
    names_to = "Method"
  )

error_u_d %>% 
  ggplot(
    aes(
      x = FL, 
      y = DL_u_d, 
      color = Method
    )
  ) +
  geom_line()
```

```{r}
error_u_d_var <- tibble(
  FL = seq(1, 50, by = 1),
  t = seq(1, 50, by = 1)
  ) %>% 
  expand(FL, t) %>% 
  mutate(
    a = 0.7,
    F0 = 0.0000000000000001,
    error_raman = (2 * raman_standard_error),
    error_nanoSIMS = (2 * nanoSIMS_standard_error),
    DLR_u_d = calculate_turnover(
      a = a,
      FT = error_raman,
      FL = FL,
      t = t,
      F0 = F0
    ),
    DLN_u_d = calculate_turnover(
      a = a,
      FT = error_nanoSIMS,
      FL = FL,
      t = t,
      F0 = F0
    )
) %>% 
  pivot_longer(
    cols = c(DLR_u_d, DLN_u_d),
    values_to = "DL_u_d",
    names_to = "Method"
  )

p_error_u_d_var <- error_u_d_var%>% 
  ggplot(
    aes(
      x = FL, 
      y = DL_u_d, 
      color = t
    )
  ) +
  geom_point() +
  facet_wrap(vars(Method), scales = "free") +
  scale_y_log10()
plotly::ggplotly(p_error_u_d_var)
```
